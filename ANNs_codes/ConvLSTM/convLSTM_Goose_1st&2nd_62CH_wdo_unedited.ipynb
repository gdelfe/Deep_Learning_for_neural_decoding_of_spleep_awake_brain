{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to print weight for convLSTM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "from ConvLSTM_pytorch import convlstm\n",
    "import operator\n",
    "from utils_v4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected subset of dates. \n",
    "val_dates = ['180409','180412','180414']\n",
    "test_dates = ['180411', '180413']\n",
    "bad_dates = ['180326', '180328', '171019', '180715', '180716', '180717']\n",
    "load_path = '/home/bijanadmin/Desktop/Goose_data/data_Goose_all_2/'\n",
    "model_saving_path = '/home/bijanadmin/Desktop/Goose_data/data_Goose_all_2/convLSTM_models'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_new(load_path, bad_dates, T_length=10, proceed=1): \n",
    "    sleep_files = os.listdir(load_path+'sleep/')\n",
    "    move_files = os.listdir(load_path+'move/')\n",
    "    all_files = sleep_files+move_files\n",
    "    \n",
    "    dic = {}\n",
    "    for f in all_files:\n",
    "        mvmt_type = f.split('_')[-1].split('.')[0]\n",
    "        date = f.split('_')[0]\n",
    "        rec = f.split('_')[1].split('_')[0]\n",
    "        time = float(f.split('_')[3][4:])\n",
    "        if date in bad_dates:\n",
    "            continue\n",
    "        if mvmt_type == 'sleep':\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        if date in dic:\n",
    "            if rec in dic[date]:\n",
    "                dic[date][rec].append([f, label, mvmt_type, date, rec, time])\n",
    "            else:\n",
    "                dic[date][rec] = [[f, label, mvmt_type, date, rec, time]]\n",
    "        else:\n",
    "            dic[date] = {rec: [[f, label, mvmt_type, date, rec, time]]}\n",
    "        \n",
    "    for d in dic:\n",
    "        for r in dic[d]:\n",
    "            dic[d][r] = sorted(dic[d][r], key=operator.itemgetter(3, 4, 5))\n",
    "    \n",
    "    move_data, sleep_data = [], []\n",
    "    for d in dic:\n",
    "        for r in dic[d]:\n",
    "            sleep_grouped, move_grouped = create_files_new_helper(dic[d][r], T_length=T_length, proceed=proceed)\n",
    "            sleep_data.append(sleep_grouped)\n",
    "            move_data.append(move_grouped)\n",
    "    \n",
    "    return move_data, sleep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_new_helper(L, T_length, proceed):\n",
    "    L_labels = np.array([L[i][1] for i in range(len(L))])\n",
    "    L_times = np.array([L[i][-1] for i in range(len(L))])\n",
    "    \n",
    "    L_new_sleep, L_new_move = [], []\n",
    "    start = 0\n",
    "    while start <= len(L)-T_length:\n",
    "        end = start + T_length\n",
    "        #pdb.pm()\n",
    "        if sum(L_times[start+1:end]-L_times[start:end-1]-time_window) != 0:\n",
    "            start += 1\n",
    "            continue\n",
    "        if sum(L_labels[start:end]) == T_length:\n",
    "            L_new_sleep.append(L[start:end])\n",
    "        elif sum(L_labels[start:end]) == 0:\n",
    "            L_new_move.append(L[start:end])\n",
    "        start += proceed\n",
    "    return L_new_sleep, L_new_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(train_files):\n",
    "    train_sleep = [i for i in train_files if i[0][1] == 1]\n",
    "    train_move = [i for i in train_files if i[0][1] == 0]\n",
    "    diff = abs(len(train_sleep)-len(train_move))\n",
    "    train_new = []\n",
    "    d = 0\n",
    "    while d < diff:\n",
    "        if len(train_sleep) > len(train_move):\n",
    "            ind = random.randint(0, len(train_move)-1)\n",
    "            x = train_move[ind]\n",
    "            d += 1\n",
    "        else:\n",
    "            ind = random.randint(0, len(train_sleep)-1)\n",
    "            x = train_sleep[ind]\n",
    "            d += 1\n",
    "        train_new.append(x)   \n",
    "    train_files = train_sleep+train_move+train_new\n",
    "    return train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDatasetAtt(Dataset):\n",
    "    def __init__(self, files, load_path, T_length, all_label=False, CH=None):\n",
    "        self.CH = CH\n",
    "        self.files = files\n",
    "        self.load_path = load_path\n",
    "        self.T_length = T_length\n",
    "        self.all_label = all_label\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        group = self.files[idx]\n",
    "        specs, labels, dates, recs, times = [], [], [], [], []\n",
    "        for i in range(len(group)):\n",
    "            f, label, mvmt_type, date, rec, time = group[i]\n",
    "            spec = torch.from_numpy(np.load(self.load_path+mvmt_type+'/'+f))\n",
    "            if self.CH is not None:\n",
    "                spec = torch.transpose(spec[self.CH,:,:].unsqueeze(0), 2, 1)\n",
    "            else:\n",
    "                spec = torch.transpose(spec, 2, 1)\n",
    "            specs.append(spec)\n",
    "            labels.append(torch.Tensor([label]))\n",
    "            dates.append(date)\n",
    "            recs.append(rec)\n",
    "            times.append(time)\n",
    "            if i == (self.T_length-1)/2:\n",
    "                label_mid = torch.Tensor([label])\n",
    "                date_mid = date\n",
    "                rec_mid = rec\n",
    "                time_mid = time\n",
    "        if self.all_label:\n",
    "            return specs, labels, dates, recs, times\n",
    "        else:\n",
    "            return specs, label_mid, date_mid, rec_mid, time_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10\n",
    "## Load files\n",
    "move_files, sleep_files = create_files_new(load_path, bad_dates, T_length=3, proceed=3)\n",
    "train_files, val_files, test_files = [], [], []\n",
    "\n",
    "## Put files in val, test, and train\n",
    "for f in move_files+sleep_files:\n",
    "    if f:\n",
    "        if f[0][1][3] in val_dates:\n",
    "            val_files.extend(f)\n",
    "        elif f[0][1][3] in test_dates:\n",
    "            test_files.extend(f)\n",
    "        else:\n",
    "            train_files.extend(f)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly shuffle inside train, val, and test\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upsample train\n",
    "train_files = upsample(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files), len(val_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load files to dataloader\n",
    "\n",
    "train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=3, all_label=True)\n",
    "valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=3, all_label=True)\n",
    "test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=3, all_label=True)\n",
    "\n",
    "# train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle = True)\n",
    "val_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Model\n",
    "class convLSTM(nn.Module):\n",
    "    def __init__(self, input_dim = 1, layers = 1, hidden_dim = 10, frequencies = 100,timewindow = 10, output_size=1, batch_size=128):\n",
    "        super(convLSTM, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.freqs = frequencies\n",
    "        self.timewindow = timewindow\n",
    "        \n",
    "        # Define the lstm layer\n",
    "        self.convLSTM = convlstm.ConvLSTM(input_dim=self.input_dim,\n",
    "                 hidden_dim=self.hidden_dim,\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=self.n_layers,\n",
    "                 batch_first=False,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False)\n",
    "        # Define the fully-connected layer\n",
    "#         self.fc = nn.Linear(self.n_layers*self.hidden_dim, output_size)\n",
    "        self.fc = nn.Linear(self.hidden_dim*self.freqs*self.timewindow, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        \n",
    "        # convLSTM\n",
    "        _, last_states = self.convLSTM(input_seq)\n",
    "        last_states = last_states[0][0]\n",
    "        last_states = last_states.reshape(last_states.shape[0], -1)\n",
    "        fc = self.fc(last_states)        \n",
    "\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader, device='cuda', collect_result = False):\n",
    "    \"\"\"\n",
    "    Function that calculate the accuracy of the model. \n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred, labs = [],[]\n",
    "    with torch.no_grad():\n",
    "        for data, labels, _, _, _ in loader:\n",
    "            # Labels\n",
    "            labels = torch.stack(labels)\n",
    "            labels = labels[0]\n",
    "            labels = labels.to(device).float()\n",
    "            # Data\n",
    "            data = torch.tensor(np.stack(data)).to(device).float() \n",
    "            data = data.to(device).float()\n",
    "            # Feed data to model\n",
    "            outputs = model(data)            \n",
    "            outputs = torch.tensor(outputs).to(device)\n",
    "            # Predictions\n",
    "            predictions = (outputs > 0.5) * 1.0\n",
    "            predictions = predictions.flatten().detach().cpu().numpy()\n",
    "            labels = labels.flatten().cpu().numpy()\n",
    "            # Calculate Accuracy\n",
    "            total += len(labels)\n",
    "            correct += (predictions == labels).sum()\n",
    "            \n",
    "            if collect_result:\n",
    "                pred.append(predictions)\n",
    "                labs.append(labels)\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    if collect_result:\n",
    "        return accuracy, pred, labs\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Function that train the model. \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_losses = 0\n",
    "    epoch_lens = 0\n",
    "    parameter_history = []\n",
    "    # criterion = nn.BCELoss()\n",
    "    for batch_idx, (data, labels, _, _, _) in enumerate(loader):\n",
    "        # Get Label\n",
    "        labels = torch.stack(labels)\n",
    "        labels = labels[0]\n",
    "        labels = torch.flatten(labels).to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "#         print(batch_idx)\n",
    "        \n",
    "        # Get data\n",
    "        data = torch.tensor(np.stack(data)).to(device).float() \n",
    "        data = data.to(device).float()\n",
    "\n",
    "        # Zero out grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Data in model\n",
    "        outputs = model(data)\n",
    "#         outputs = torch.tensor(outputs,requires_grad = True).to(device)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "\n",
    "        # Get loss\n",
    "        loss = criterion(torch.sigmoid(outputs), labels)\n",
    "#         print(loss)\n",
    "        epoch_losses += loss\n",
    "        epoch_lens += 1\n",
    "\n",
    "        parameter_history.append(list(model.parameters())[0])\n",
    "        loss.backward() # error?\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_accs = get_accuracy(model, loader, device=device, collect_result = False)\n",
    "    return epoch_losses/epoch_lens, epoch_accs, parameter_history\n",
    "\n",
    "def evaluate(model, optimizer, criterion, loader, device='cuda', collect_result = False):\n",
    "    model.eval()\n",
    "    epoch_losses = 0\n",
    "    epoch_lens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels, _, _, _) in enumerate(loader):\n",
    "            labels = torch.stack(labels)\n",
    "            labels = labels[0]\n",
    "            labels = labels.to(device).float()\n",
    "            labels = torch.flatten(labels).to(device).float()\n",
    "            data = torch.tensor(np.stack(data)).to(device).float() \n",
    "            data = data.to(device).float()\n",
    "            outputs = model(data)\n",
    "#             outputs = torch.tensor(outputs).to(device)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            loss = criterion(torch.sigmoid(outputs), labels)\n",
    "            epoch_losses += loss\n",
    "            epoch_lens += 1\n",
    "    \n",
    "    if collect_result:\n",
    "        epoch_accs, pred, labs = get_accuracy(model, loader, device = device, collect_result = True)\n",
    "        return epoch_losses/epoch_lens,epoch_accs, pred, labs\n",
    "    else:\n",
    "        epoch_accs = get_accuracy(model, loader, device=device, collect_result = collect_result)\n",
    "    return epoch_losses/epoch_lens, epoch_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "tol = 0.01\n",
    "learning_rate = 0.01\n",
    "num_epochs = 51\n",
    "alpha = 0\n",
    "model_type = 'convLSTM'\n",
    "loss_type = 'bce'\n",
    "reg_type = 'none'\n",
    "alpha = 0\n",
    "timewindow = 10\n",
    "ch = 'all'\n",
    "tlength = 3\n",
    "# verbose = False\n",
    "\n",
    "\n",
    "model = convLSTM(input_dim = 62).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss() # BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses, val_accs, parameter_history = [], [], [], [],[]\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, parameter_history = train(model, optimizer, criterion, train_loader,  device='cuda')\n",
    "    val_loss, val_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    if val_loss <= min(val_losses):\n",
    "        best_epoch = epoch\n",
    "        print(epoch)\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, tlength,epoch))\n",
    "#     elif verbose:\n",
    "    else:\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        \n",
    "#     if epoch == num_epochs-1:\n",
    "#         torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_EPOCH{}.pt'.format(model_saving_path, model_type, CH, loss_type, reg_type, alpha, timewindow, epoch))\n",
    "\n",
    "plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_trainresult.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, tlength)\n",
    "print(train_result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = {'model_type': model_type, 'train_losses' : train_losses, 'val_losses' : val_losses, 'train_accs': train_accs, 'val_accs': val_accs}\n",
    "\n",
    "pickle.dump( train_result, open( train_result_filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pickle.load(open(train_result_filename, \"rb\" ))\n",
    "plot_loss_acc( train_result['train_losses'],  train_result['val_losses'],  train_result['train_accs'],  train_result['val_accs'],  train_result['model_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_convLSTM = os.listdir(model_saving_path)\n",
    "results = []\n",
    "best_result = 0\n",
    "reg_alpha = 'REG'+reg_type+str(alpha)+'_'\n",
    "for i, s in enumerate(model_convLSTM):\n",
    "    if 'convLSTM_CHall_' in s and reg_alpha in s and 'trainresult' not in s:\n",
    "        model_name = model_convLSTM[i].split('_')\n",
    "        epoch_name = [ind for ind,item in enumerate(np.array(model_name)) if \"EPOCH\" in item]\n",
    "        res = [int(i) for i in model_name[epoch_name[0]] if i.isdigit()]\n",
    "        if len(res) > 1:\n",
    "            epoch_result = res[0]*10+res[1]\n",
    "        else:\n",
    "            epoch_result = res[0]\n",
    "        if epoch_result>best_result and epoch_result != 50:\n",
    "            best_result = epoch_result\n",
    "\n",
    "results.append([alpha,best_result])\n",
    "\n",
    "    \n",
    "results = pd.DataFrame(np.array(results), columns=['alpha', 'epoch'])\n",
    "best_results = results.groupby('alpha').max('epoch')\n",
    "print(best_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_length = 3\n",
    "for i,(index,row) in enumerate(best_results.iterrows()):\n",
    "\n",
    "    best_epoch = int(row)\n",
    "    alpha = index\n",
    "    \n",
    "    \n",
    "    # load best model\n",
    "    model = convLSTM(input_dim = 62).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    model.load_state_dict(torch.load('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length, best_epoch)))\n",
    "    \n",
    "    print('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow,T_length, best_epoch))\n",
    "\n",
    "    \n",
    "    ## Calculate validation accuracy and validation loss\n",
    "    val_loss, val_acc, val_preds, val_labels = evaluate(model, optimizer, criterion, val_loader, device='cuda', collect_result = True)\n",
    "    print('validation loss:{} accuracy:{}'.format(val_loss, val_acc))\n",
    "    \n",
    "#     ## Calculate test accuracy and test loss\n",
    "# #     test_loss, test_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "# #     print('test loss:{} accuracy:{}'.format(test_loss, test_acc))\n",
    "# #     print(np.mean(np.concatenate(test_labels)))\n",
    "    \n",
    "    ## Confusion matrix-validation\n",
    "    predictions_val = np.concatenate(val_preds)\n",
    "    labels_val = np.concatenate(val_labels)\n",
    "    \n",
    "    val_cm_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_valcm.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length)\n",
    "    print(val_cm_filename)\n",
    "    val_cm_result = {'predictions_val': predictions_val, 'labels_val' : labels_val}\n",
    "\n",
    "    pickle.dump( val_cm_result, open( val_cm_filename, \"wb\" ) )\n",
    "    \n",
    "    \n",
    "    df_val = pd.DataFrame({'predictions': predictions_val, 'labels': labels_val})\n",
    "\n",
    "    cm_val = confusion_matrix(labels_val, predictions_val)\n",
    "    ax = plt.axes()\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm_val.flatten()]\n",
    "\n",
    "    TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "    FPR = 1 - TNR\n",
    "    TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "    FNR = 1-TPR\n",
    "    group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         group_percentages]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sn.heatmap(cm_val, annot=labels, fmt='', center = 2000)\n",
    "    ax.set_title('Validation Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "#     ## Confusion matrix-test\n",
    "#     predictions_test = np.concatenate(test_preds)\n",
    "#     labels_test = np.concatenate(test_labels)\n",
    "\n",
    "#     df_test = pd.DataFrame({'predictions': predictions_test, 'labels': labels_test})\n",
    "\n",
    "#     cm_test = confusion_matrix(labels_test, predictions_test)\n",
    "#     ax = plt.axes()\n",
    "#     group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#     group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "#                     cm_test.flatten()]\n",
    "\n",
    "#     TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "#     FPR = 1 - TNR\n",
    "#     TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "#     FNR = 1-TPR\n",
    "#     group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "#     group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "#                          group_percentages]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "#               zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "#     sn.heatmap(cm_test, annot=labels, fmt='', center = 2000)\n",
    "#     ax.set_title('Test Confusion Matrix')\n",
    "#     ax.set_xlabel('Predicted Label')\n",
    "#     ax.set_ylabel('True Label')\n",
    "#     plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10\n",
    "## Load files\n",
    "move_files, sleep_files = create_files_new(load_path, bad_dates, T_length=3, proceed=3)\n",
    "train_files, val_files, test_files = [], [], []\n",
    "\n",
    "## Put files in val, test, and train\n",
    "for f in move_files+sleep_files:\n",
    "    if f:\n",
    "        if f[0][1][3] in val_dates:\n",
    "            val_files.extend(f)\n",
    "        elif f[0][1][3] in test_dates:\n",
    "            test_files.extend(f)\n",
    "        else:\n",
    "            train_files.extend(f)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly shuffle inside train, val, and test\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upsample train\n",
    "train_files = upsample(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files), len(val_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load files to dataloader\n",
    "T_length = 5\n",
    "\n",
    "train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "\n",
    "# train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle = True)\n",
    "val_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "tol = 0.01\n",
    "learning_rate = 0.01\n",
    "num_epochs = 51\n",
    "alpha = 0\n",
    "model_type = 'convLSTM'\n",
    "loss_type = 'bce'\n",
    "reg_type = 'none'\n",
    "alpha = 0\n",
    "timewindow = 10\n",
    "ch = 'all'\n",
    "# verbose = False\n",
    "\n",
    "\n",
    "model = convLSTM(input_dim = 62).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss() # BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses, val_accs, parameter_history = [], [], [], [],[]\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, parameter_history = train(model, optimizer, criterion, train_loader,  device='cuda')\n",
    "    val_loss, val_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    if val_loss <= min(val_losses):\n",
    "        best_epoch = epoch\n",
    "        print(epoch)\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length, epoch))\n",
    "#     elif verbose:\n",
    "    else:\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        \n",
    "#     if epoch == num_epochs-1:\n",
    "#         torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_EPOCH{}.pt'.format(model_saving_path, model_type, CH, loss_type, reg_type, alpha, timewindow, epoch))\n",
    "\n",
    "plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_trainresult.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length)\n",
    "print(train_result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = {'model_type': model_type, 'train_losses' : train_losses, 'val_losses' : val_losses, 'train_accs': train_accs, 'val_accs': val_accs}\n",
    "\n",
    "pickle.dump( train_result, open( train_result_filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pickle.load(open(train_result_filename, \"rb\" ))\n",
    "plot_loss_acc( train_result['train_losses'],  train_result['val_losses'],  train_result['train_accs'],  train_result['val_accs'],  train_result['model_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_convLSTM = os.listdir(model_saving_path)\n",
    "results = []\n",
    "best_result = 0\n",
    "reg_alpha = 'REG'+reg_type+str(alpha)+'_'\n",
    "tlength = 'TLENGTH'+str(T_length)\n",
    "for i, s in enumerate(model_convLSTM):\n",
    "    if 'convLSTM_CHall_' in s and reg_alpha in s and 'trainresult' not in s and tlength in s and 'valcm' not in s:\n",
    "        model_name = model_convLSTM[i].split('_')\n",
    "        epoch_name = [ind for ind,item in enumerate(np.array(model_name)) if \"EPOCH\" in item]\n",
    "        res = [int(i) for i in model_name[epoch_name[0]] if i.isdigit()]\n",
    "        if len(res) > 1:\n",
    "            epoch_result = res[0]*10+res[1]\n",
    "        else:\n",
    "            epoch_result = res[0]\n",
    "        if epoch_result>best_result and epoch_result != 50:\n",
    "            best_result = epoch_result\n",
    "\n",
    "results.append([alpha,best_result])\n",
    "\n",
    "    \n",
    "results = pd.DataFrame(np.array(results), columns=['alpha', 'epoch'])\n",
    "best_results = results.groupby('alpha').max('epoch')\n",
    "print(best_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(index,row) in enumerate(best_results.iterrows()):\n",
    "\n",
    "    best_epoch = int(row)\n",
    "    alpha = index\n",
    "    \n",
    "    \n",
    "    # load best model\n",
    "    model = convLSTM(input_dim = 62).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    model.load_state_dict(torch.load('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length, best_epoch)))\n",
    "    \n",
    "    print('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow,T_length, best_epoch))\n",
    "\n",
    "    \n",
    "    ## Calculate validation accuracy and validation loss\n",
    "    val_loss, val_acc, val_preds, val_labels = evaluate(model, optimizer, criterion, val_loader, device='cuda', collect_result = True)\n",
    "    print('validation loss:{} accuracy:{}'.format(val_loss, val_acc))\n",
    "    \n",
    "#     ## Calculate test accuracy and test loss\n",
    "# #     test_loss, test_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "# #     print('test loss:{} accuracy:{}'.format(test_loss, test_acc))\n",
    "# #     print(np.mean(np.concatenate(test_labels)))\n",
    "    \n",
    "    ## Confusion matrix-validation\n",
    "    predictions_val = np.concatenate(val_preds)\n",
    "    labels_val = np.concatenate(val_labels)\n",
    "    \n",
    "    val_cm_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_valcm.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length)\n",
    "    print(val_cm_filename)\n",
    "    val_cm_result = {'predictions_val': predictions_val, 'labels_val' : labels_val}\n",
    "\n",
    "    pickle.dump( val_cm_result, open( val_cm_filename, \"wb\" ) )\n",
    "    \n",
    "    \n",
    "    df_val = pd.DataFrame({'predictions': predictions_val, 'labels': labels_val})\n",
    "\n",
    "    cm_val = confusion_matrix(labels_val, predictions_val)\n",
    "    ax = plt.axes()\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm_val.flatten()]\n",
    "\n",
    "    TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "    FPR = 1 - TNR\n",
    "    TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "    FNR = 1-TPR\n",
    "    group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         group_percentages]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sn.heatmap(cm_val, annot=labels, fmt='', center = 2000)\n",
    "    ax.set_title('Validation Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "#     ## Confusion matrix-test\n",
    "#     predictions_test = np.concatenate(test_preds)\n",
    "#     labels_test = np.concatenate(test_labels)\n",
    "\n",
    "#     df_test = pd.DataFrame({'predictions': predictions_test, 'labels': labels_test})\n",
    "\n",
    "#     cm_test = confusion_matrix(labels_test, predictions_test)\n",
    "#     ax = plt.axes()\n",
    "#     group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#     group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "#                     cm_test.flatten()]\n",
    "\n",
    "#     TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "#     FPR = 1 - TNR\n",
    "#     TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "#     FNR = 1-TPR\n",
    "#     group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "#     group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "#                          group_percentages]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "#               zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "#     sn.heatmap(cm_test, annot=labels, fmt='', center = 2000)\n",
    "#     ax.set_title('Test Confusion Matrix')\n",
    "#     ax.set_xlabel('Predicted Label')\n",
    "#     ax.set_ylabel('True Label')\n",
    "#     plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 10\n",
    "## Load files\n",
    "move_files, sleep_files = create_files_new(load_path, bad_dates, T_length=3, proceed=3)\n",
    "train_files, val_files, test_files = [], [], []\n",
    "\n",
    "## Put files in val, test, and train\n",
    "for f in move_files+sleep_files:\n",
    "    if f:\n",
    "        if f[0][1][3] in val_dates:\n",
    "            val_files.extend(f)\n",
    "        elif f[0][1][3] in test_dates:\n",
    "            test_files.extend(f)\n",
    "        else:\n",
    "            train_files.extend(f)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly shuffle inside train, val, and test\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upsample train\n",
    "train_files = upsample(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files), len(val_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load files to dataloader\n",
    "T_length = 10\n",
    "\n",
    "train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=T_length, all_label=True)\n",
    "\n",
    "# train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "# test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle = True)\n",
    "val_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "tol = 0.01\n",
    "learning_rate = 0.01\n",
    "num_epochs = 51\n",
    "alpha = 0\n",
    "model_type = 'convLSTM'\n",
    "loss_type = 'bce'\n",
    "reg_type = 'none'\n",
    "alpha = 0\n",
    "timewindow = 10\n",
    "ch = 'all'\n",
    "# verbose = False\n",
    "\n",
    "\n",
    "model = convLSTM(input_dim = 62).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss() # BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, train_accs, val_losses, val_accs, parameter_history = [], [], [], [],[]\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, parameter_history = train(model, optimizer, criterion, train_loader,  device='cuda')\n",
    "    val_loss, val_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    if val_loss <= min(val_losses):\n",
    "        best_epoch = epoch\n",
    "        print(epoch)\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length, epoch))\n",
    "#     elif verbose:\n",
    "    else:\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        \n",
    "#     if epoch == num_epochs-1:\n",
    "#         torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_EPOCH{}.pt'.format(model_saving_path, model_type, CH, loss_type, reg_type, alpha, timewindow, epoch))\n",
    "\n",
    "plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_trainresult.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length)\n",
    "print(train_result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = {'model_type': model_type, 'train_losses' : train_losses, 'val_losses' : val_losses, 'train_accs': train_accs, 'val_accs': val_accs}\n",
    "\n",
    "pickle.dump( train_result, open( train_result_filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pickle.load(open(train_result_filename, \"rb\" ))\n",
    "plot_loss_acc( train_result['train_losses'],  train_result['val_losses'],  train_result['train_accs'],  train_result['val_accs'],  train_result['model_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_convLSTM = os.listdir(model_saving_path)\n",
    "results = []\n",
    "best_result = 0\n",
    "reg_alpha = 'REG'+reg_type+str(alpha)+'_'\n",
    "tlength = 'TLENGTH'+str(T_length)\n",
    "for i, s in enumerate(model_convLSTM):\n",
    "    if 'convLSTM_CHall_' in s and reg_alpha in s and 'trainresult' not in s and tlength in s and 'valcm' not in s:\n",
    "        model_name = model_convLSTM[i].split('_')\n",
    "        epoch_name = [ind for ind,item in enumerate(np.array(model_name)) if \"EPOCH\" in item]\n",
    "        res = [int(i) for i in model_name[epoch_name[0]] if i.isdigit()]\n",
    "        if len(res) > 1:\n",
    "            epoch_result = res[0]*10+res[1]\n",
    "        else:\n",
    "            epoch_result = res[0]\n",
    "        if epoch_result>best_result and epoch_result != 50:\n",
    "            best_result = epoch_result\n",
    "\n",
    "results.append([alpha,best_result])\n",
    "\n",
    "    \n",
    "results = pd.DataFrame(np.array(results), columns=['alpha', 'epoch'])\n",
    "best_results = results.groupby('alpha').max('epoch')\n",
    "print(best_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(index,row) in enumerate(best_results.iterrows()):\n",
    "\n",
    "    best_epoch = int(row)\n",
    "    alpha = index\n",
    "    \n",
    "    \n",
    "    # load best model\n",
    "    model = convLSTM(input_dim = 62).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    model.load_state_dict(torch.load('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length, best_epoch)))\n",
    "    \n",
    "    print('{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_EPOCH{}.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow,T_length, best_epoch))\n",
    "\n",
    "    \n",
    "    ## Calculate validation accuracy and validation loss\n",
    "    val_loss, val_acc, val_preds, val_labels = evaluate(model, optimizer, criterion, val_loader, device='cuda', collect_result = True)\n",
    "    print('validation loss:{} accuracy:{}'.format(val_loss, val_acc))\n",
    "    \n",
    "#     ## Calculate test accuracy and test loss\n",
    "# #     test_loss, test_acc = evaluate(model, optimizer, criterion, val_loader, device='cuda')\n",
    "# #     print('test loss:{} accuracy:{}'.format(test_loss, test_acc))\n",
    "# #     print(np.mean(np.concatenate(test_labels)))\n",
    "    \n",
    "    ## Confusion matrix-validation\n",
    "    predictions_val = np.concatenate(val_preds)\n",
    "    labels_val = np.concatenate(val_labels)\n",
    "    \n",
    "    val_cm_filename = '{}/{}_CH{}_LOSS{}_REG{}{}_TW{}_TLENGTH{}_valcm.pt'.format(model_saving_path, model_type, ch, loss_type, reg_type, alpha, timewindow, T_length)\n",
    "    print(val_cm_filename)\n",
    "    val_cm_result = {'predictions_val': predictions_val, 'labels_val' : labels_val}\n",
    "\n",
    "    pickle.dump( val_cm_result, open( val_cm_filename, \"wb\" ) )\n",
    "    \n",
    "    \n",
    "    df_val = pd.DataFrame({'predictions': predictions_val, 'labels': labels_val})\n",
    "\n",
    "    cm_val = confusion_matrix(labels_val, predictions_val)\n",
    "    ax = plt.axes()\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm_val.flatten()]\n",
    "\n",
    "    TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "    FPR = 1 - TNR\n",
    "    TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "    FNR = 1-TPR\n",
    "    group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         group_percentages]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sn.heatmap(cm_val, annot=labels, fmt='', center = 2000)\n",
    "    ax.set_title('Validation Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    plt.show()\n",
    "    \n",
    "#     ## Confusion matrix-test\n",
    "#     predictions_test = np.concatenate(test_preds)\n",
    "#     labels_test = np.concatenate(test_labels)\n",
    "\n",
    "#     df_test = pd.DataFrame({'predictions': predictions_test, 'labels': labels_test})\n",
    "\n",
    "#     cm_test = confusion_matrix(labels_test, predictions_test)\n",
    "#     ax = plt.axes()\n",
    "#     group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "#     group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "#                     cm_test.flatten()]\n",
    "\n",
    "#     TNR = int(group_counts[0]) / (int(group_counts[0])+int(group_counts[1]))\n",
    "#     FPR = 1 - TNR\n",
    "#     TPR = int(group_counts[3]) / (int(group_counts[3])+int(group_counts[2]))\n",
    "#     FNR = 1-TPR\n",
    "#     group_percentages =[TNR, FPR, FNR, TPR]\n",
    "\n",
    "#     group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "#                          group_percentages]\n",
    "#     labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "#               zip(group_names,group_counts,group_percentages)]\n",
    "#     labels = np.asarray(labels).reshape(2,2)\n",
    "#     sn.heatmap(cm_test, annot=labels, fmt='', center = 2000)\n",
    "#     ax.set_title('Test Confusion Matrix')\n",
    "#     ax.set_xlabel('Predicted Label')\n",
    "#     ax.set_ylabel('True Label')\n",
    "#     plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
