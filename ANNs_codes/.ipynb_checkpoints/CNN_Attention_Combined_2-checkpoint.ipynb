{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import operator\n",
    "import pdb\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define \n",
    "channel, width of each spectrogram in the time direction and bad dates (with artifacts), validation dates, test dates, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH = 23\n",
    "time_window = 10 # width of the spectrogram in the time direction \n",
    "T_length = 3 # how many spectrograms grouped together\n",
    "proceed = 1 # Parameter controlling overlap across spectrogram. 1 = max overalp, T_length-1 = no overlap\n",
    "device = torch.device('cuda')\n",
    "bad_dates = ['180326', '180328', '171019', '180715', '180716', '180717']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dates = ['180327','180329']\n",
    "test_dates = ['180330','180331']\n",
    "load_path = '/home/bijanadmin/Desktop/Goose_data/data_Goose_1st_2/'\n",
    "# save_path = '/mnt/pesaranlab/People/Capstone_students/Yue/model/model_presentation_yue/model_Goose_1st'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180324_003_62_time1036.0_sleep.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_files = os.listdir(load_path+'sleep/')\n",
    "move_files = os.listdir(load_path+'move/')\n",
    "all_files = sleep_files+move_files\n",
    "f = all_files[0]\n",
    "print(f)\n",
    "f.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear GPU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the data set and make it into grouped spectrograms (windows)\n",
    "The function assigns the label 1 to sleep and label 0 to movement, creates a dictionary to store the data set and groups the data into sets of spectrograms by calling the function create_files_new_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_new(load_path, bad_dates, T_length=10, proceed=1): \n",
    "    sleep_files = os.listdir(load_path+'sleep/')\n",
    "    move_files = os.listdir(load_path+'move/')\n",
    "    all_files = sleep_files+move_files\n",
    "    \n",
    "    dic = {}\n",
    "    for f in all_files:\n",
    "        mvmt_type = f.split('_')[-1].split('.')[0]\n",
    "        date = f.split('_')[0]\n",
    "        rec = f.split('_')[1].split('_')[0]\n",
    "        time = float(f.split('_')[3][4:])\n",
    "        if date in bad_dates:\n",
    "            continue\n",
    "        if mvmt_type == 'sleep':\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        if date in dic:\n",
    "            if rec in dic[date]:\n",
    "                dic[date][rec].append([f, label, mvmt_type, date, rec, time])\n",
    "            else:\n",
    "                dic[date][rec] = [[f, label, mvmt_type, date, rec, time]]\n",
    "        else:\n",
    "            dic[date] = {rec: [[f, label, mvmt_type, date, rec, time]]}\n",
    "        \n",
    "    for d in dic:\n",
    "        for r in dic[d]:\n",
    "            dic[d][r] = sorted(dic[d][r], key=operator.itemgetter(3, 4, 5))\n",
    "    \n",
    "    move_data, sleep_data = [], []\n",
    "    for d in dic:\n",
    "        for r in dic[d]:\n",
    "            sleep_grouped, move_grouped = create_files_new_helper(dic[d][r], T_length=T_length, proceed=proceed)\n",
    "            sleep_data.append(sleep_grouped)\n",
    "            move_data.append(move_grouped)\n",
    "    \n",
    "    return move_data, sleep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to group  a set of spectrogram windows together\n",
    "T_length = number of spectrograms grouped together <br>\n",
    "time_window = width of each spectrogram in the time direction <br>\n",
    "proceed =  number of time overlaps across different windows. <br> Proceed = 1, max overlap. Proceed = time_window-1, no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_new_helper(L, T_length, proceed):\n",
    "    L_labels = np.array([L[i][1] for i in range(len(L))])\n",
    "    L_times = np.array([L[i][-1] for i in range(len(L))])\n",
    "    \n",
    "    L_new_sleep, L_new_move = [], []\n",
    "    start = 0\n",
    "    while start <= len(L)-T_length:\n",
    "        end = start + T_length\n",
    "        #pdb.pm()\n",
    "        if sum(L_times[start+1:end]-L_times[start:end-1]-time_window) != 0:\n",
    "            start += 1\n",
    "            continue\n",
    "        if sum(L_labels[start:end]) == T_length:\n",
    "            L_new_sleep.append(L[start:end])\n",
    "        elif sum(L_labels[start:end]) == 0:\n",
    "            L_new_move.append(L[start:end])\n",
    "        start += proceed\n",
    "        \n",
    "    return L_new_sleep, L_new_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files, sleep_files = create_files_new(load_path, bad_dates, T_length=T_length, proceed=proceed)\n",
    "train_files, val_files, test_files = [], [], []\n",
    "for f in move_files+sleep_files:\n",
    "    if f:\n",
    "        if f[0][1][3] in val_dates:\n",
    "            val_files.extend(f)\n",
    "        elif f[0][1][3] in test_dates:\n",
    "            test_files.extend(f)\n",
    "        else:\n",
    "            train_files.extend(f)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random shuffle the data across groups\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(val_files)\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202440"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)*10 + len(val_files)*10 + len(test_files)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample smaller TRAINING data set (movement) in order to have a balanced sleep/movement data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(train_files):\n",
    "    train_sleep = [i for i in train_files if i[0][1] == 1]\n",
    "    train_move = [i for i in train_files if i[0][1] == 0]\n",
    "    diff = abs(len(train_sleep)-len(train_move))\n",
    "    train_new = []\n",
    "    d = 0\n",
    "    while d < diff:\n",
    "        if len(train_sleep) > len(train_move):\n",
    "            ind = random.randint(0, len(train_move)-1)\n",
    "            x = train_move[ind]\n",
    "            d += 1\n",
    "        else:\n",
    "            ind = random.randint(0, len(train_sleep)-1)\n",
    "            x = train_sleep[ind]\n",
    "            d += 1\n",
    "        train_new.append(x)   \n",
    "    train_files = train_sleep+train_move+train_new\n",
    "    return train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = upsample(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balance val \n",
    "sleep_files = []\n",
    "move_files = []\n",
    "for t in range(len(val_files)):\n",
    "    if 'sleep' in val_files[t][0]:\n",
    "        sleep_files.append(val_files[t])\n",
    "    if 'move' in val_files[t][0]:\n",
    "        move_files.append(val_files[t])\n",
    "\n",
    "sleep_sample = sample(sleep_files, len(move_files))\n",
    "val_2_files = sleep_sample+move_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data volume:  17266\n",
      "validation data volume:  2004\n",
      "rate val/train 0.12\n"
     ]
    }
   ],
   "source": [
    "print('training data volume: ',len(train_files))\n",
    "print('validation data volume: ',len(val_2_files))\n",
    "print('rate val/train {:.2f}'.format(len(val_2_files)/len(train_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Set - Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDatasetAtt(Dataset):\n",
    "    def __init__(self, files, load_path, T_length, all_label=False, CH=None):\n",
    "        self.CH = CH\n",
    "        self.files = files\n",
    "        self.load_path = load_path\n",
    "        self.T_length = T_length\n",
    "        self.all_label = all_label\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        group = self.files[idx]\n",
    "        specs, labels, dates, recs, times = [], [], [], [], []\n",
    "        \n",
    "        for i in range(len(group)): # for each window in the group \n",
    "            f, label, mvmt_type, date, rec, time = group[i]\n",
    "            spec = torch.from_numpy(np.load(self.load_path+mvmt_type+'/'+f)) # load the spectrogram file\n",
    "            if self.CH is not None: \n",
    "                # get spectrogram for specific channel\n",
    "                spec = torch.transpose(spec[self.CH,:,:].unsqueeze(0), 2, 1) # careful with the dimensions order here \n",
    "            else:\n",
    "                # get spectrograms for 62 channels \n",
    "                spec = torch.transpose(spec, 2, 1) # careful with the dimension order here \n",
    "            # append spectrograms and metadata\n",
    "            specs.append(spec)\n",
    "            labels.append(torch.Tensor([label]))\n",
    "            dates.append(date)\n",
    "            recs.append(rec)\n",
    "            times.append(time)\n",
    "            if i == (self.T_length-1)/2: # what happens if T_length is even?\n",
    "                label_mid = torch.Tensor([label])\n",
    "                date_mid = date\n",
    "                rec_mid = rec\n",
    "                time_mid = time\n",
    "        if self.all_label:\n",
    "            return specs, labels, dates, recs, times\n",
    "        else:\n",
    "            return specs, label_mid, date_mid, rec_mid, time_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDatasetAtt(Dataset):\n",
    "    def __init__(self, files, load_path, T_length, all_label=False, CH=None):\n",
    "        self.CH = CH\n",
    "        self.files = files\n",
    "        self.load_path = load_path\n",
    "        self.T_length = T_length\n",
    "        self.all_label = all_label\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        group = self.files[idx]\n",
    "        specs, labels, dates, recs, times = [], [], [], [], []\n",
    "        for i in range(len(group)):\n",
    "            f, label, mvmt_type, date, rec, time = group[i]\n",
    "            spec = torch.from_numpy(np.load(self.load_path+mvmt_type+'/'+f))\n",
    "            if self.CH is not None:\n",
    "                spec = torch.transpose(spec[self.CH,:,:].unsqueeze(0), 2, 1)\n",
    "            else:\n",
    "                spec = torch.transpose(spec, 2, 1)\n",
    "            specs.append(spec)\n",
    "            labels.append(torch.Tensor([label]))\n",
    "            dates.append(date)\n",
    "            recs.append(rec)\n",
    "            times.append(time)\n",
    "            if (self.all_label==False) and (i == (self.T_length-1)/2):\n",
    "                labels = torch.Tensor([label])\n",
    "                dates = date\n",
    "                recs = rec\n",
    "                times = time\n",
    "            \n",
    "        return specs, labels, dates, recs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpectrogramDatasetAtt(files=train_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "valid_dataset = SpectrogramDatasetAtt(files=val_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "test_dataset = SpectrogramDatasetAtt(files=test_files, load_path=load_path, T_length=3, all_label=False, CH=CH)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle = False)\n",
    "val_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle = False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for specs, labels, dates, recs, times in train_loader:\n",
    "    break\n",
    "specs[0].shape\n",
    "labels.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if input makes sense\n",
    "plt.imshow(specs[0][0, 0, :, :])\n",
    "plt.yticks(ticks=[0, 20, 40, 60, 80, 99], labels=[round(np.logspace(0, 2.45, 100)[i]) for i in [0, 20, 40, 60, 80, 99]])\n",
    "plt.xticks(ticks=[0, 9], labels=[1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding_init(n_position, emb_dim):\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / emb_dim) for j in range(emb_dim)]\n",
    "        if pos != 0 else np.zeros(emb_dim) for pos in range(n_position)])\n",
    "    \n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # apply sin on 0th,2nd,4th...emb_dim\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # apply cos on 1st,3rd,5th...emb_dim\n",
    "    return torch.from_numpy(position_enc).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = position_encoding_init(10, 30).numpy().T\n",
    "plt.imshow(a)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader, device='cuda'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels, _, _, _ in loader:\n",
    "            labels = torch.stack(labels).transpose(1,0)\n",
    "            labels = labels.to(device).float()\n",
    "            data = torch.stack(data).transpose(1,0)\n",
    "            data = data.to(device).float()\n",
    "            data_pos = torch.LongTensor([list(range(T_length))]).to(device)\n",
    "            outputs = model(data, data_pos)\n",
    "            \n",
    "            predictions = (outputs > 0.5) * 1.0\n",
    "            predictions = predictions.flatten().detach().cpu().numpy()\n",
    "            labels = labels.flatten().cpu().numpy()\n",
    "            total += len(labels)\n",
    "            correct += (predictions == labels).sum()\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader, T_length, device='cuda'):\n",
    "    model.train()\n",
    "    epoch_losses = 0\n",
    "    epoch_lens = 0\n",
    "    \n",
    "    # criterion = nn.BCELoss()\n",
    "    \n",
    "    for batch_idx, (data, labels, _, _, _) in enumerate(loader):\n",
    "        pdb.set_trace()\n",
    "        labels = torch.stack(labels).transpose(1,0)\n",
    "        pdb.set_trace()\n",
    "        labels = labels.to(device).float()\n",
    "        data = torch.stack(data).transpose(1,0)\n",
    "        data = data.to(device).float()\n",
    "        data_pos = torch.LongTensor([list(range(T_length))]).to(device)\n",
    "        outputs = model(data, data_pos)\n",
    "        pdb.set_trace()\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_losses += loss\n",
    "        epoch_lens += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Will back propogation work correctly?\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_accs = get_accuracy(model, loader, device=device)\n",
    "    return epoch_losses/epoch_lens, epoch_accs\n",
    "\n",
    "def evaluate(model, optimizer, criterion, loader, T_length, device='cuda'):\n",
    "    model.eval()\n",
    "    epoch_losses = 0\n",
    "    epoch_lens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels, _, _, _) in enumerate(loader):\n",
    "            labels = torch.stack(labels).transpose(1,0)\n",
    "            labels = labels.to(device).float()\n",
    "            data = torch.stack(data).transpose(1,0)\n",
    "            data = data.to(device).float()\n",
    "            data_pos = torch.LongTensor([list(range(T_length))]).to(device)\n",
    "            outputs = model(data, data_pos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_losses += loss\n",
    "            epoch_lens += 1\n",
    "    \n",
    "    epoch_accs = get_accuracy(model, loader, device=device)\n",
    "    return epoch_losses/epoch_lens, epoch_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN and Attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# https://github.com/heykeetae/Self-Attention-GAN/blob/master/sagan_models.py\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, p_dropout, out_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        self.bn1 = nn.BatchNorm2d(2)\n",
    "        self.bn2 = nn.BatchNorm2d(4)\n",
    "        self.fc1 = nn.Linear(4*25*2, out_dim)\n",
    "              \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = x.float()\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.shape[0],-1) \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x) # last CNN MLP output becomes the input of the Attention module \n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Attention1(nn.Module):\n",
    "    def __init__(self, att_dim, T_length, p_dropout_att, all_label=False):\n",
    "        super(Attention1, self).__init__()\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.position_enc = nn.Embedding(T_length, att_dim)\n",
    "        self.position_enc.weight.data = position_encoding_init(T_length, att_dim)\n",
    "\n",
    "        # Attention\n",
    "        self.query = nn.Linear(att_dim, att_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1) # every slice along dim will sum to 1\n",
    "        self.ff1 = nn.Linear(att_dim, att_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ff2 = nn.Linear(att_dim, att_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(att_dim, 1) # paper uses 2 layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(p_dropout_att)\n",
    "       \n",
    "        self.T_length = T_length\n",
    "        self.all_label = all_label\n",
    "        \n",
    "    def forward(self, x, x_pos):\n",
    "        x = x.float()        \n",
    "#         x += self.position_enc(x_pos)\n",
    "        \n",
    "        Q = self.query(x)  # Q = X*W + B\n",
    "#         Q = self.dropout(Q)\n",
    "        \n",
    "        energy =  torch.bmm(Q, x.permute(0, 2, 1)) # Q*X_T\n",
    "        attention = self.softmax(self.tanh(energy)) # alpha\n",
    "#         attention = self.softmax(energy)\n",
    "        x_att = torch.bmm(attention, x) # Attention \n",
    "\n",
    "        x_att = self.dropout(x_att)\n",
    "#         x_output = torch.sigmoid(self.fc(x_att))\n",
    "#         x_att = self.ff2(self.relu(self.ff1(x_att)))\n",
    "#         x_att = self.dropout(x_att)\n",
    "        x_output = torch.sigmoid(self.fc(x_att))\n",
    "      \n",
    "        if self.all_label:\n",
    "            return x_output\n",
    "        return x_output[:, int((self.T_length-1)/2), :]\n",
    "\n",
    "class CNN_ATT(nn.Module):\n",
    "    def __init__(self, p_dropout, p_dropout_att, att_dim, T_length, all_label):\n",
    "        super(CNN_ATT, self).__init__()\n",
    "        self.cnn = CNN(p_dropout, att_dim)\n",
    "        self.att = Attention1(att_dim, T_length, all_label)\n",
    "        self.T_length = T_length\n",
    "        self.att_dim = att_dim\n",
    "    \n",
    "    def forward(self, x, x_pos):\n",
    "        CNN_outputs = torch.zeros(x.shape[0], x.shape[1], self.att_dim, device='cuda') # create tensor to store CNN outputs \n",
    "        for t in range(self.T_length):\n",
    "            x_t = x[:, t, :].float()\n",
    "            CNN_outputs[:, t, :] = self.cnn(x_t)\n",
    "        Att_outputs = self.att(CNN_outputs, x_pos)\n",
    "        \n",
    "        return Att_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify models and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_ATT(\n",
       "  (cnn): CNN(\n",
       "    (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "  )\n",
       "  (att): Attention1(\n",
       "    (position_enc): Embedding(3, 128)\n",
       "    (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (ff1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (ff2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=False, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 31\n",
    "model_type = 'CNN-Attention'\n",
    "loss_type = 'bce'\n",
    "p_dropout = 0.2\n",
    "p_dropout_att = 0.2\n",
    "att_dim = 128\n",
    "T_length = 3\n",
    "all_label = False\n",
    "verbose = True\n",
    "\n",
    "model = CNN_ATT(p_dropout, p_dropout_att, att_dim, T_length, all_label).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss() # BCE loss\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_ATT(\n",
       "  (cnn): CNN(\n",
       "    (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "  )\n",
       "  (att): Attention1(\n",
       "    (position_enc): Embedding(3, 128)\n",
       "    (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (ff1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (ff2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=False, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data) # initialize all the Feed Forward (MLP) layer\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data) # initialize convolutional layers \n",
    "    \n",
    "torch.manual_seed(90)\n",
    "model.apply(weights_init)\n",
    "# torch.nn.init.xavier_uniform_(model.cnn.conv1.weight)\n",
    "# model.cnn.conv2.weight\n",
    "# model.att.query.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-149-f5176acede31>\u001b[0m(10)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      8 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> labels.T\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n",
      "ipdb> torch.stack(labels)\n",
      "*** TypeError: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor\n",
      "ipdb> labels.T\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n",
      "ipdb> labels.T.shape\n",
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Attention1 (separate dates, upsample only train, all labels for Attention1)\n",
    "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, optimizer, criterion, train_loader, T_length=T_length, device='cuda')\n",
    "    val_loss, val_acc = evaluate(model, optimizer, criterion, val_loader, T_length=T_length, device='cuda')\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    if val_loss <= min(val_losses):\n",
    "        best_epoch = epoch\n",
    "        print(epoch)\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "        # torch.save(model_CNN.state_dict(), '{}/{}_CH{}_LOSS{}_TW{}_TLEN{}_DROP{}_ATTDIM{}_EPOCH{}.pt'.format(path, model_type, CH, loss_type, time_window, T_length, p_dropout, att_dim, epoch))\n",
    "        # torch.save(model_Att.state_dict(), '{}/{}_CH{}_LOSS{}_TW{}_TLEN{}_DROP{}_ATTDIM{}_EPOCH{}.pt'.format(path, model_type, CH, loss_type, time_window, T_length, p_dropout, att_dim, epoch))\n",
    "    elif verbose:\n",
    "        print('Train loss for epoch {}: {}'.format(epoch, train_loss))\n",
    "        print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
    "    if epoch % 10 == 0:\n",
    "        plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)\n",
    "        \n",
    "    # if epoch == num_epochs-1:\n",
    "        # torch.save(model.state_dict(), '{}/{}_CH{}_LOSS{}_TW{}_TLEN{}_DROP{}_ATTDIM{}_EPOCH{}.pt'.format(path, model_type, CH, loss_type, time_window, T_length, p_dropout, att_dim, epoch))\n",
    "        # torch.save(model_CNN.state_dict(), '{}/{}_CH{}_LOSS{}_TW{}_TLEN{}_DROP{}_ATTDIM{}_EPOCH{}.pt'.format(path, model_type, CH, loss_type, time_window, T_length, p_dropout, att_dim, epoch))\n",
    "\n",
    "plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_loss_acc(train_losses, val_losses, train_accs, val_accs, model_type)\n",
    "fig.savefig(load_path + 'figures/Goose_1st/'+'CNN_Attention_short_model_with_pos_enc_no_Q_drop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
